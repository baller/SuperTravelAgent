"""
AgentBase é‡æ„ç‰ˆæœ¬

æ™ºèƒ½ä½“åŸºç±»ï¼Œæä¾›æ‰€æœ‰æ™ºèƒ½ä½“çš„é€šç”¨åŠŸèƒ½å’Œæ¥å£ã€‚
æ”¹è¿›äº†ä»£ç ç»“æ„ã€é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•å’Œå¯ç»´æŠ¤æ€§ã€‚

ä½œè€…: Eric ZZ
ç‰ˆæœ¬: 2.0 (é‡æ„ç‰ˆ)
"""

from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional, Generator
import re,json
import uuid
import time
from agents.utils.logger import logger
from agents.tool.tool_base import AgentToolSpec
import traceback


class AgentBase(ABC):
    """
    æ™ºèƒ½ä½“åŸºç±»
    
    ä¸ºæ‰€æœ‰æ™ºèƒ½ä½“æä¾›é€šç”¨åŠŸèƒ½å’Œæ¥å£ï¼ŒåŒ…æ‹¬æ¶ˆæ¯å¤„ç†ã€å·¥å…·è½¬æ¢ã€
    æµå¼å¤„ç†å’Œå†…å®¹è§£æç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚
    """

    def __init__(self, model: Any, model_config: Dict[str, Any], system_prefix: str = ""):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“åŸºç±»
        
        Args:
            model: å¯æ‰§è¡Œçš„è¯­è¨€æ¨¡å‹å®ä¾‹
            model_config: æ¨¡å‹é…ç½®å‚æ•°
            system_prefix: ç³»ç»Ÿå‰ç¼€æç¤º
        """
        self.model = model
        self.model_config = model_config
        self.system_prefix = system_prefix
        self.agent_description = f"{self.__class__.__name__} agent"
        
        # Tokenä½¿ç”¨ç»Ÿè®¡
        self.token_stats = {
            'total_calls': 0,
            'total_input_tokens': 0,
            'total_output_tokens': 0,
            'total_cached_tokens': 0,
            'total_reasoning_tokens': 0,
            'step_details': []  # è¯¦ç»†çš„æ¯æ­¥è®°å½•
        }
        
        logger.debug(f"AgentBase: åˆå§‹åŒ– {self.__class__.__name__}ï¼Œæ¨¡å‹é…ç½®: {model_config}")
    
    def _track_token_usage(self, response, step_name: str, start_time: float = None):
        """
        è·Ÿè¸ªæ¨¡å‹è°ƒç”¨çš„tokenä½¿ç”¨æƒ…å†µ
        
        Args:
            response: æ¨¡å‹å“åº”å¯¹è±¡
            step_name: æ­¥éª¤åç§°ï¼ˆå¦‚"task_analysis", "planning", "execution"ç­‰ï¼‰
            start_time: å¼€å§‹æ—¶é—´æˆ³
        """
        if hasattr(response, 'usage') and response.usage:
            usage = response.usage
            
            # æå–tokenä¿¡æ¯
            input_tokens = getattr(usage, 'prompt_tokens', 0)
            output_tokens = getattr(usage, 'completion_tokens', 0)
            total_tokens = getattr(usage, 'total_tokens', input_tokens + output_tokens)
            
            # å¤„ç†ä¸åŒæ¨¡å‹çš„ç‰¹æ®Šå­—æ®µ - ä¿®å¤å¯¹è±¡è®¿é—®æ–¹å¼
            cached_tokens = 0
            reasoning_tokens = 0
            
            # å¤„ç†prompt_tokens_details
            if hasattr(usage, 'prompt_tokens_details') and usage.prompt_tokens_details:
                if hasattr(usage.prompt_tokens_details, 'cached_tokens'):
                    cached_tokens = getattr(usage.prompt_tokens_details, 'cached_tokens', 0) or 0
            else:
                # å…¼å®¹æ€§å¤„ç†ï¼ŒæŸäº›æ¨¡å‹å¯èƒ½ç›´æ¥åœ¨usageå¯¹è±¡ä¸Šæœ‰cached_tokens
                cached_tokens = getattr(usage, 'cached_tokens', 0) or 0
            
            # å¤„ç†completion_tokens_details  
            if hasattr(usage, 'completion_tokens_details') and usage.completion_tokens_details:
                if hasattr(usage.completion_tokens_details, 'reasoning_tokens'):
                    reasoning_tokens = getattr(usage.completion_tokens_details, 'reasoning_tokens', 0) or 0
            else:
                # å…¼å®¹æ€§å¤„ç†ï¼ŒæŸäº›æ¨¡å‹å¯èƒ½ç›´æ¥åœ¨usageå¯¹è±¡ä¸Šæœ‰reasoning_tokens
                reasoning_tokens = getattr(usage, 'reasoning_tokens', 0) or 0
            
            # æ›´æ–°ç»Ÿè®¡
            self.token_stats['total_calls'] += 1
            self.token_stats['total_input_tokens'] += input_tokens
            self.token_stats['total_output_tokens'] += output_tokens
            self.token_stats['total_cached_tokens'] += cached_tokens
            self.token_stats['total_reasoning_tokens'] += reasoning_tokens
            
            # è®°å½•è¯¦ç»†æ­¥éª¤
            execution_time = time.time() - start_time if start_time else 0
            step_detail = {
                'step': step_name,
                'agent': self.__class__.__name__,
                'input_tokens': input_tokens,
                'output_tokens': output_tokens,
                'cached_tokens': cached_tokens,
                'reasoning_tokens': reasoning_tokens,
                'total_tokens': total_tokens,
                'execution_time': round(execution_time, 2),
                'timestamp': time.time()
            }
            self.token_stats['step_details'].append(step_detail)
            
            logger.info(f"{self.__class__.__name__}: {step_name} - è¾“å…¥:{input_tokens}, è¾“å‡º:{output_tokens}, ç¼“å­˜:{cached_tokens}, æ¨ç†:{reasoning_tokens}, æ€»è®¡:{total_tokens} tokens, è€—æ—¶:{execution_time:.2f}s")
    
    def _track_streaming_token_usage(self, chunks, step_name: str, start_time: float = None):
        """
        è·Ÿè¸ªæµå¼å“åº”çš„tokenä½¿ç”¨æƒ…å†µ
        
        Args:
            chunks: æµå¼å“åº”çš„æ‰€æœ‰chunks
            step_name: æ­¥éª¤åç§°
            start_time: å¼€å§‹æ—¶é—´æˆ³
        """
        # è®°å½•è°ƒè¯•ä¿¡æ¯
        logger.debug(f"{self.__class__.__name__}: å¼€å§‹è·Ÿè¸ªæµå¼tokenä½¿ç”¨ï¼Œæ”¶åˆ° {len(chunks)} ä¸ªchunks")
        
        # å¯¹äºæµå¼å“åº”ï¼Œåªä½¿ç”¨æœ€åä¸€ä¸ªåŒ…å«usageä¿¡æ¯çš„chunkï¼Œé¿å…é‡å¤ç»Ÿè®¡
        final_usage_chunk = None
        for chunk in reversed(chunks):  # ä»åå¾€å‰æ‰¾ï¼Œä½¿ç”¨æœ€åçš„usageä¿¡æ¯
            if hasattr(chunk, 'usage') and chunk.usage:
                final_usage_chunk = chunk
                logger.debug(f"{self.__class__.__name__}: æ‰¾åˆ°æœ€ç»ˆusageä¿¡æ¯")
                break
        
        if final_usage_chunk:
            logger.debug(f"{self.__class__.__name__}: ä½¿ç”¨æœ€ç»ˆchunkä¸­çš„usageä¿¡æ¯è¿›è¡Œtokenè·Ÿè¸ª")
            self._track_token_usage(final_usage_chunk, step_name, start_time)
        else:
            # å¦‚æœæ²¡æœ‰usageä¿¡æ¯ï¼Œè®°å½•ä¸€ä¸ªç©ºè°ƒç”¨ä½†è®¡ç®—execution_time
            self.token_stats['total_calls'] += 1
            execution_time = time.time() - start_time if start_time else 0
            step_detail = {
                'step': step_name,
                'agent': self.__class__.__name__,
                'input_tokens': 0,
                'output_tokens': 0,
                'cached_tokens': 0,
                'reasoning_tokens': 0,
                'total_tokens': 0,
                'execution_time': round(execution_time, 2),
                'timestamp': time.time(),
                'note': f'No usage info in {len(chunks)} chunks'
            }
            self.token_stats['step_details'].append(step_detail)
            logger.warning(f"{self.__class__.__name__}: {step_name} - æ— æ³•ä» {len(chunks)} ä¸ªchunksä¸­è·å–tokenä½¿ç”¨ä¿¡æ¯ï¼Œè€—æ—¶:{execution_time:.2f}s")
    
    def get_token_stats(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰agentçš„tokenä½¿ç”¨ç»Ÿè®¡
        
        Returns:
            Dict[str, Any]: Tokenä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            'agent_name': self.__class__.__name__,
            **self.token_stats
        }
    
    def reset_token_stats(self):
        """é‡ç½®tokenç»Ÿè®¡"""
        self.token_stats = {
            'total_calls': 0,
            'total_input_tokens': 0,
            'total_output_tokens': 0,
            'total_cached_tokens': 0,
            'total_reasoning_tokens': 0,
            'step_details': []
        }
        logger.debug(f"{self.__class__.__name__}: Tokenç»Ÿè®¡å·²é‡ç½®")
    
    def print_token_stats(self):
        """æ‰“å°å½“å‰agentçš„tokenä½¿ç”¨ç»Ÿè®¡"""
        stats = self.get_token_stats()
        print(f"\nğŸ¤– {stats['agent_name']} Tokenä½¿ç”¨ç»Ÿè®¡:")
        print(f"  ğŸ“ è°ƒç”¨æ¬¡æ•°: {stats['total_calls']}")
        print(f"  ğŸ“¥ è¾“å…¥tokens: {stats['total_input_tokens']}")
        print(f"  ğŸ“¤ è¾“å‡ºtokens: {stats['total_output_tokens']}")
        print(f"  ğŸƒ ç¼“å­˜tokens: {stats['total_cached_tokens']}")
        print(f"  ğŸ§  æ¨ç†tokens: {stats['total_reasoning_tokens']}")
        print(f"  ğŸ”¢ æ€»è®¡tokens: {stats['total_input_tokens'] + stats['total_output_tokens']}")
        
        if stats['step_details']:
            print(f"  ğŸ“‹ è¯¦ç»†æ­¥éª¤:")
            for detail in stats['step_details']:
                print(f"    â€¢ {detail['step']}: è¾“å…¥{detail['input_tokens']}, è¾“å‡º{detail['output_tokens']}, æ€»è®¡{detail['total_tokens']} tokens, è€—æ—¶{detail['execution_time']}s")

    def _call_llm_streaming(self, messages: List[Dict[str, Any]]):
        """
        é€šç”¨çš„æµå¼æ¨¡å‹è°ƒç”¨æ–¹æ³•
        
        Args:
            messages: è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            Generator: è¯­è¨€æ¨¡å‹çš„æµå¼å“åº”
        """
        logger.debug(f"{self.__class__.__name__}: è°ƒç”¨è¯­è¨€æ¨¡å‹è¿›è¡Œæµå¼ç”Ÿæˆ")
        
        return self.model.chat.completions.create(
            messages=messages,
            stream=True,
            stream_options={"include_usage": True},
            **self.model_config
        )
    
    def _call_llm_non_streaming(self, messages: List[Dict[str, Any]]):
        """
        é€šç”¨çš„éæµå¼æ¨¡å‹è°ƒç”¨æ–¹æ³•
        
        Args:
            messages: è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            æ¨¡å‹å“åº”å¯¹è±¡
        """
        logger.debug(f"{self.__class__.__name__}: è°ƒç”¨è¯­è¨€æ¨¡å‹è¿›è¡Œéæµå¼ç”Ÿæˆ")
        
        return self.model.chat.completions.create(
            messages=messages,
            stream=False,
            **self.model_config
        )
    
    def _create_message_chunk(self, 
                            content: str, 
                            message_id: str, 
                            show_content: str,
                            message_type: str = 'assistant',
                            role: str = 'assistant') -> List[Dict[str, Any]]:
        """
        åˆ›å»ºé€šç”¨çš„æ¶ˆæ¯å—
        
        Args:
            content: æ¶ˆæ¯å†…å®¹
            message_id: æ¶ˆæ¯ID
            show_content: æ˜¾ç¤ºå†…å®¹
            message_type: æ¶ˆæ¯ç±»å‹
            role: æ¶ˆæ¯è§’è‰²
            
        Returns:
            List[Dict[str, Any]]: æ ¼å¼åŒ–çš„æ¶ˆæ¯å—åˆ—è¡¨
        """
        message_chunk = {
            'role': role,
            'content': content,
            'type': message_type,
            'message_id': message_id,
            'show_content': show_content
        }
            
        return [message_chunk]
    
    def _handle_error_generic(self, 
                            error: Exception, 
                            error_context: str,
                            message_type: str = 'error') -> Generator[List[Dict[str, Any]], None, None]:
        """
        é€šç”¨çš„é”™è¯¯å¤„ç†æ–¹æ³•
        
        Args:
            error: å‘ç”Ÿçš„å¼‚å¸¸
            error_context: é”™è¯¯ä¸Šä¸‹æ–‡æè¿°
            message_type: æ¶ˆæ¯ç±»å‹
            
        Yields:
            List[Dict[str, Any]]: é”™è¯¯æ¶ˆæ¯å—
        """
        logger.error(f"{self.__class__.__name__}: {error_context}é”™è¯¯: {str(error)}")
        
        error_message = f"\n{error_context}å¤±è´¥: {str(error)}"
        message_id = str(uuid.uuid4())
        
        yield [{
            'role': 'tool',
            'content': error_message,
            'type': message_type,
            'message_id': message_id,
            'show_content': error_message
        }]
    
    def _execute_streaming_with_token_tracking(self, 
                                             prompt: str, 
                                             step_name: str,
                                             system_message: Optional[Dict[str, Any]] = None,
                                             message_type: str = 'assistant') -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œæµå¼å¤„ç†å¹¶è·Ÿè¸ªtokenä½¿ç”¨
        
        Args:
            prompt: ç”¨æˆ·æç¤º
            step_name: æ­¥éª¤åç§°ï¼ˆç”¨äºtokenç»Ÿè®¡ï¼‰
            system_message: å¯é€‰çš„ç³»ç»Ÿæ¶ˆæ¯
            message_type: æ¶ˆæ¯ç±»å‹
            
        Yields:
            List[Dict[str, Any]]: æµå¼è¾“å‡ºçš„æ¶ˆæ¯å—
        """
        logger.info(f"{self.__class__.__name__}: å¼€å§‹æ‰§è¡Œæµå¼{step_name}")
        
        message_id = str(uuid.uuid4())
        
        # å‡†å¤‡æ¶ˆæ¯
        if system_message:
            messages = [system_message, {"role": "user", "content": prompt}]
        else:
            messages = [{"role": "user", "content": prompt}]
        
        # æ‰§è¡Œæµå¼å¤„ç†
        chunk_count = 0
        start_time = time.time()
        
        # æ”¶é›†æ‰€æœ‰chunksä»¥ä¾¿è·Ÿè¸ªtokenä½¿ç”¨
        chunks = []
        for chunk in self._call_llm_streaming(messages):
            chunks.append(chunk)
            if len(chunk.choices) ==0:
                continue
            if chunk.choices[0].delta.content:
                delta_content = chunk.choices[0].delta.content
                chunk_count += 1
                
                # ä¼ é€’usageä¿¡æ¯åˆ°æ¶ˆæ¯å—
                yield self._create_message_chunk(
                    content=delta_content,
                    message_id=message_id,
                    show_content=delta_content,
                    message_type=message_type
                )
        
        # è·Ÿè¸ªtokenä½¿ç”¨æƒ…å†µ
        self._track_streaming_token_usage(chunks, step_name, start_time)
        
        logger.info(f"{self.__class__.__name__}: æµå¼{step_name}å®Œæˆï¼Œå…±ç”Ÿæˆ {chunk_count} ä¸ªæ–‡æœ¬å—")
        
        # å‘é€ç»“æŸæ ‡è®°ï¼ˆä¹ŸåŒ…å«æœ€ç»ˆçš„usageä¿¡æ¯ï¼‰
        yield self._create_message_chunk(
            content="",
            message_id=message_id,
            show_content="\n",
            message_type=message_type
        )
    
    def prepare_unified_system_message(self,
                                     session_id: Optional[str] = None,
                                     system_context: Optional[Dict[str, Any]] = None,
                                     custom_prefix: Optional[str] = None) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„ç³»ç»Ÿæ¶ˆæ¯ç”Ÿæˆæ–¹æ³•
        
        è¿™ä¸ªæ–¹æ³•ä¼šè‡ªåŠ¨ä½¿ç”¨æ¯ä¸ªagentå®šä¹‰çš„SYSTEM_PREFIX_DEFAULTå¸¸é‡ï¼Œ
        å¦‚æœagentæ²¡æœ‰å®šä¹‰è¯¥å¸¸é‡ï¼Œåˆ™ä½¿ç”¨ä¼ å…¥çš„custom_prefixæˆ–é»˜è®¤çš„system_prefixã€‚
        
        Args:
            session_id: ä¼šè¯IDï¼ˆå‘åå…¼å®¹ï¼Œç°åœ¨å¯ä»system_contextè·å–ï¼‰
            system_context: è¿è¡Œæ—¶ç³»ç»Ÿä¸Šä¸‹æ–‡å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰éœ€è¦çš„ä¿¡æ¯
            custom_prefix: è‡ªå®šä¹‰å‰ç¼€ï¼Œå¦‚æœagentæ²¡æœ‰SYSTEM_PREFIX_DEFAULTæ—¶ä½¿ç”¨
            
        Returns:
            Dict[str, Any]: ç»Ÿä¸€æ ¼å¼çš„ç³»ç»Ÿæ¶ˆæ¯å­—å…¸
        """
        logger.debug(f"{self.__class__.__name__}: ç”Ÿæˆç»Ÿä¸€ç³»ç»Ÿæ¶ˆæ¯")
        
        # 1. ç¡®å®šç³»ç»Ÿå‰ç¼€
        system_prefix = self._get_system_prefix(custom_prefix)
        
        # 2. æ„å»ºåŸºç¡€ç³»ç»Ÿå†…å®¹
        system_content = system_prefix
        
        # 3. æ·»åŠ è¿è¡Œæ—¶system_contextä¿¡æ¯
        if system_context:
            system_content += self._build_system_context_section(system_context)
        
        logger.debug(f"{self.__class__.__name__}: ç³»ç»Ÿæ¶ˆæ¯ç”Ÿæˆå®Œæˆï¼Œæ€»é•¿åº¦: {len(system_content)}")
        
        # 4. æ‰“å°å®Œæ•´çš„ç³»ç»Ÿæç¤ºä¿¡æ¯ï¼ˆæ–°å¢ï¼‰
        print("\n" + "="*100)
        print(f"ğŸ¤– {self.__class__.__name__} - ç³»ç»Ÿæç¤ºæ¶ˆæ¯")
        print("="*100)
        print(f"ğŸ“‹ Agentç±»å‹: {self.__class__.__name__}")
        print(f"ğŸ†” ä¼šè¯ID: {session_id if session_id else system_context.get('session_id', 'None') if system_context else 'None'}")
        
        if system_context:
            print(f"ğŸ”§ System Contextå­—æ®µ: {list(system_context.keys())}")
            print(f"ğŸ“Š System Contextè¯¦æƒ…:")
            for key, value in system_context.items():
                if isinstance(value, str) and len(value) > 100:
                    print(f"   â€¢ {key}: {value[:100]}... (é•¿åº¦: {len(value)})")
                else:
                    print(f"   â€¢ {key}: {value}")
        else:
            print("ğŸ”§ System Context: None")
        
        print(f"ğŸ“ å®Œæ•´ç³»ç»Ÿæ¶ˆæ¯é•¿åº¦: {len(system_content)} å­—ç¬¦")
        print("ğŸ“ å®Œæ•´ç³»ç»Ÿæ¶ˆæ¯å†…å®¹:")
        print("-" * 50)
        print(system_content)
        print("-" * 50)
        print("="*100 + "\n")
        
        return {
            'role': 'system',
            'content': system_content
        }
    
    def _get_system_prefix(self, custom_prefix: Optional[str] = None) -> str:
        """
        è·å–ç³»ç»Ÿå‰ç¼€
        
        ä¼˜å…ˆçº§ï¼š
        1. agentçš„SYSTEM_PREFIX_DEFAULTå¸¸é‡
        2. custom_prefixå‚æ•°
        3. agentçš„system_prefixå®ä¾‹å˜é‡
        4. é»˜è®¤æè¿°
        
        Args:
            custom_prefix: è‡ªå®šä¹‰å‰ç¼€
            
        Returns:
            str: æœ€ç»ˆçš„ç³»ç»Ÿå‰ç¼€
        """
        # ä¼˜å…ˆä½¿ç”¨agentå®šä¹‰çš„SYSTEM_PREFIX_DEFAULTå¸¸é‡
        if hasattr(self, 'SYSTEM_PREFIX_DEFAULT'):
            return self.SYSTEM_PREFIX_DEFAULT
        
        # å…¶æ¬¡ä½¿ç”¨ä¼ å…¥çš„custom_prefix
        if custom_prefix:
            return custom_prefix
        
        # å†æ¬¡ä½¿ç”¨å®ä¾‹çš„system_prefix
        if self.system_prefix:
            return self.system_prefix
        
        # æœ€åä½¿ç”¨é»˜è®¤æè¿°
        return f"ä½ æ˜¯ä¸€ä¸ª{self.__class__.__name__}æ™ºèƒ½ä½“ã€‚"
    
    def _build_system_context_section(self, system_context: Dict[str, Any]) -> str:
        """
        æ„å»ºè¿è¡Œæ—¶system_contextä¿¡æ¯éƒ¨åˆ†
        
        Args:
            system_context: è¿è¡Œæ—¶ç³»ç»Ÿä¸Šä¸‹æ–‡å­—å…¸
            
        Returns:
            str: æ ¼å¼åŒ–çš„system_contextå­—ç¬¦ä¸²
        """
        logger.debug(f"{self.__class__.__name__}: æ·»åŠ è¿è¡Œæ—¶system_contextåˆ°ç³»ç»Ÿæ¶ˆæ¯")
        section = "\n\nè¡¥å……ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š\n"
        
        for key, value in system_context.items():
            if isinstance(value, dict):
                # å¦‚æœå€¼æ˜¯å­—å…¸ï¼Œæ ¼å¼åŒ–æ˜¾ç¤º
                formatted_dict = json.dumps(value, ensure_ascii=False, indent=2)
                section += f"{key}: {formatted_dict}\n"
            elif isinstance(value, (list, tuple)):
                # å¦‚æœå€¼æ˜¯åˆ—è¡¨æˆ–å…ƒç»„ï¼Œæ ¼å¼åŒ–æ˜¾ç¤º
                formatted_list = json.dumps(list(value), ensure_ascii=False, indent=2)
                section += f"{key}: {formatted_list}\n"
            else:
                # å…¶ä»–ç±»å‹ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                section += f"{key}: {str(value)}\n"
        
        return section

    @abstractmethod
    def run_stream(self, 
                   messages: List[Dict[str, Any]], 
                   tool_manager: Optional[Any] = None,
                   session_id: str = None,
                   system_context: Optional[Dict[str, Any]] = None) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æµå¼å¤„ç†æ¶ˆæ¯çš„æŠ½è±¡æ–¹æ³•
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å¯é€‰çš„å·¥å…·ç®¡ç†å™¨
            session_id: ä¼šè¯ID
            system_context: è¿è¡Œæ—¶ç³»ç»Ÿä¸Šä¸‹æ–‡å­—å…¸ï¼ŒåŒ…å«åŸºç¡€ä¿¡æ¯å’Œç”¨æˆ·è‡ªå®šä¹‰ä¿¡æ¯
            
        Yields:
            List[Dict[str, Any]]: æµå¼è¾“å‡ºçš„æ¶ˆæ¯å—
        """
        pass

    def run(self, 
            messages: List[Dict[str, Any]], 
            tool_manager: Optional[Any] = None,
            session_id: str = None,
            system_context: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        æ‰§è¡ŒAgentä»»åŠ¡ï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
        
        é»˜è®¤å®ç°ï¼šæ”¶é›†æµå¼è¾“å‡ºçš„æ‰€æœ‰å—å¹¶åˆå¹¶ä¸ºæœ€ç»ˆç»“æœ
        
        Args:
            messages: å¯¹è¯å†å²è®°å½•
            tool_manager: å·¥å…·ç®¡ç†å™¨
            session_id: ä¼šè¯ID
            system_context: è¿è¡Œæ—¶ç³»ç»Ÿä¸Šä¸‹æ–‡å­—å…¸ï¼ŒåŒ…å«åŸºç¡€ä¿¡æ¯å’Œç”¨æˆ·è‡ªå®šä¹‰ä¿¡æ¯
            
        Returns:
            List[Dict[str, Any]]: ä»»åŠ¡æ‰§è¡Œç»“æœæ¶ˆæ¯åˆ—è¡¨
        """
        logger.debug(f"AgentBase: å¼€å§‹æ‰§è¡Œéæµå¼ä»»åŠ¡ï¼ŒAgentç±»å‹: {self.__class__.__name__}")
        
        # æ”¶é›†æ‰€æœ‰æµå¼è¾“å‡ºçš„å—
        all_chunks = []
        for chunk_batch in self.run_stream(
            messages=messages,
            tool_manager=tool_manager,
            session_id=session_id,
            system_context=system_context
        ):
            all_chunks.extend(chunk_batch)
        
        # åˆå¹¶ç›¸åŒmessage_idçš„å—
        merged_messages = self._merge_chunks(all_chunks)
        
        logger.debug(f"AgentBase: éæµå¼ä»»åŠ¡å®Œæˆï¼Œè¿”å› {len(merged_messages)} æ¡åˆå¹¶æ¶ˆæ¯")
        return merged_messages

    def _log_agent_output(self, final_messages: List[Dict[str, Any]]) -> None:
        """
        è®°å½•Agentçš„å®Œæ•´è¾“å‡ºæ—¥å¿—
        
        Args:
            final_messages: Agentæœ€ç»ˆè¾“å‡ºçš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨
        """
        agent_name = self.__class__.__name__
        
        logger.info(f"ğŸ¯ {agent_name} æ‰§è¡Œå®Œæˆ!")
        logger.info(f"ğŸ“Š {agent_name} æ€»å…±è¾“å‡º {len(final_messages)} æ¡å®Œæ•´æ¶ˆæ¯")
        
        if final_messages:
            logger.info(f"ğŸ“‹ {agent_name} å®Œæ•´è¾“å‡ºmessages:")
            
            for i, msg in enumerate(final_messages):
                # ç®€åŒ–æ¶ˆæ¯å†…å®¹ä»¥ä¾¿æ—¥å¿—æŸ¥çœ‹
                simplified_msg = {
                    'role': msg.get('role', 'unknown'),
                    'type': msg.get('type', 'unknown'),
                    'message_id': msg.get('message_id', 'unknown')[:8] + '...' if msg.get('message_id') else 'none',
                    'content_length': len(str(msg.get('content', ''))),
                    'show_content_length': len(str(msg.get('show_content', '')))
                }
                
                # ç‰¹æ®Šå­—æ®µå¤„ç†
                if 'tool_calls' in msg and msg['tool_calls']:
                    simplified_msg['has_tool_calls'] = True
                    simplified_msg['tool_calls_count'] = len(msg['tool_calls'])
                if 'tool_call_id' in msg:
                    simplified_msg['tool_call_id'] = msg['tool_call_id'][:8] + '...' if len(msg['tool_call_id']) > 8 else msg['tool_call_id']
                
                # æ˜¾ç¤ºå…³é”®å†…å®¹æ‘˜è¦
                if msg.get('content'):
                    content_preview = str(msg['content'])[:100].replace('\n', ' ')
                    if len(content_preview) < len(str(msg['content'])):
                        content_preview += '...'
                    simplified_msg['content_preview'] = content_preview
                
                if msg.get('show_content'):
                    show_preview = str(msg['show_content'])[:50].replace('\n', ' ')
                    if len(show_preview) < len(str(msg['show_content'])):
                        show_preview += '...'
                    simplified_msg['show_content_preview'] = show_preview
                
                logger.info(f"  [{i+1}] {simplified_msg}")
        
        logger.info(f"ğŸ {agent_name} æ‰§è¡Œæµç¨‹ç»“æŸ")

    def to_tool(self) -> AgentToolSpec:
        """
        å°†æ™ºèƒ½ä½“è½¬æ¢ä¸ºå·¥å…·æ ¼å¼
        
        Returns:
            AgentToolSpec: åŒ…å«æ™ºèƒ½ä½“è¿è¡Œæ–¹æ³•çš„å·¥å…·è§„èŒƒ
        """
        logger.debug(f"AgentBase: å°† {self.__class__.__name__} è½¬æ¢ä¸ºå·¥å…·æ ¼å¼")
        
        tool_spec = AgentToolSpec(
            name=self.__class__.__name__,
            description=self.agent_description + '\n\n Agentç±»å‹çš„å·¥å…·ï¼Œå¯ä»¥è‡ªåŠ¨è¯»å–å†å²å¯¹è¯ï¼Œæ‰€éœ€ä¸éœ€è¦è¿è¡Œçš„å‚æ•°',
            func=self.run,
            parameters={},
            required=[]
        )
        
        return tool_spec
        

    def _extract_json_from_markdown(self, content: str) -> str:
        """
        ä»markdownä»£ç å—ä¸­æå–JSONå†…å®¹
        
        Args:
            content: å¯èƒ½åŒ…å«markdownä»£ç å—çš„å†…å®¹
            
        Returns:
            str: æå–çš„JSONå†…å®¹ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»£ç å—åˆ™è¿”å›åŸå§‹å†…å®¹
        """
        logger.debug("AgentBase: å°è¯•ä»å†…å®¹ä¸­æå–JSON")
        
        # é¦–å…ˆå°è¯•ç›´æ¥è§£æ
        try:
            json.loads(content)
            return content
        except json.JSONDecodeError:
            pass
        
        # å°è¯•ä»markdownä»£ç å—ä¸­æå–
        code_block_pattern = r'```(?:json)?\n([\s\S]*?)\n```'
        match = re.search(code_block_pattern, content)
        
        if match:
            try:
                json.loads(match.group(1))
                logger.debug("AgentBase: æˆåŠŸä»markdownä»£ç å—ä¸­æå–JSON")
                return match.group(1)
            except json.JSONDecodeError:
                logger.warning(f"AgentBase: {self.__class__.__name__} è§£æmarkdownä»£ç å—ä¸­çš„JSONå¤±è´¥")
                pass
        
        logger.debug("AgentBase: æœªæ‰¾åˆ°æœ‰æ•ˆJSONï¼Œè¿”å›åŸå§‹å†…å®¹")
        return content

    def _extract_completed_actions_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä»æ¶ˆæ¯ä¸­æå–å·²å®Œæˆçš„æ“ä½œ
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: å·²å®Œæˆæ“ä½œçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.debug(f"AgentBase: {self.__class__.__name__} ä» {len(messages)} æ¡æ¶ˆæ¯ä¸­æå–å·²å®Œæˆæ“ä½œ")
        
        completed_actions_messages = []
        
        # ä»æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¼€å§‹æå–
        for index, msg in enumerate(reversed(messages)):
            if msg['role'] == 'user':
                completed_actions_messages.extend(messages[len(messages) - index:])
                break
        
        # ç§»é™¤ä»»åŠ¡åˆ†è§£ç±»å‹çš„æ¶ˆæ¯
        completed_actions_messages = [
            msg for msg in completed_actions_messages 
            if msg.get('type') != 'task_decomposition'
        ]

        logger.debug(f"AgentBase: {self.__class__.__name__} æå–äº† {len(completed_actions_messages)} æ¡å·²å®Œæˆæ“ä½œæ¶ˆæ¯")
        return completed_actions_messages

    def _extract_task_description_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä»æ¶ˆæ¯ä¸­æå–ä»»åŠ¡æè¿°
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: ä»»åŠ¡æè¿°ç›¸å…³çš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.debug(f"AgentBase: {self.__class__.__name__} ä» {len(messages)} æ¡æ¶ˆæ¯ä¸­æå–ä»»åŠ¡æè¿°")
        
        task_description_messages = []
        
        # æå–åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸ºæ­¢
        for index, msg in enumerate(reversed(messages)):
            if msg['role'] == 'user':
                task_description_messages.extend(messages[:len(messages) - index])
                break
        
        # åªä¿ç•™æ­£å¸¸ç±»å‹å’Œæœ€ç»ˆç­”æ¡ˆç±»å‹çš„æ¶ˆæ¯
        task_description_messages = [
            msg for msg in task_description_messages 
            if msg.get('type') in ['normal', 'final_answer']
        ]

        logger.debug(f"AgentBase: {self.__class__.__name__} æå–äº† {len(task_description_messages)} æ¡ä»»åŠ¡æè¿°æ¶ˆæ¯")
        return task_description_messages

    def clean_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ¸…ç†æ¶ˆæ¯ï¼Œåªä¿ç•™OpenAIéœ€è¦çš„å­—æ®µ
        
        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: æ¸…ç†åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.debug(f"AgentBase: æ¸…ç† {len(messages)} æ¡æ¶ˆæ¯")
        
        clean_messages = []
        
        for msg in messages:
                if 'tool_calls' in msg and msg['tool_calls'] is not None:
                    clean_messages.append({
                        'role': msg['role'],
                        'tool_calls': msg['tool_calls']
                    })
                elif 'content' in msg:
                    if 'tool_call_id' in msg:
                        clean_messages.append({
                            'role': msg['role'],
                            'content': msg['content'],
                            'tool_call_id': msg['tool_call_id']
                        })
                    else:
                        clean_messages.append({
                            'role': msg['role'],
                            'content': msg['content']
                        })
        
        logger.debug(f"AgentBase: æ¸…ç†åä¿ç•™ {len(clean_messages)} æ¡æ¶ˆæ¯")
        return clean_messages

    def _merge_messages(self, 
                       all_messages: List[Dict[str, Any]], 
                       new_messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        é€šè¿‡message_idå°†æ–°æ¶ˆæ¯åˆå¹¶åˆ°ç°æœ‰æ¶ˆæ¯ä¸­
        
        Args:
            all_messages: å½“å‰å®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
            new_messages: è¦åˆå¹¶çš„æ–°æ¶ˆæ¯
            
        Returns:
            List[Dict[str, Any]]: åˆå¹¶åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        merged = []
        message_map = {}
        
        # é¦–å…ˆæ·»åŠ æ‰€æœ‰ç°æœ‰æ¶ˆæ¯
        for msg in all_messages:
            msg_copy = msg.copy()
            # ç¡®ä¿æ¶ˆæ¯æœ‰message_id
            if 'message_id' not in msg_copy:
                msg_copy['message_id'] = str(uuid.uuid4())
                logger.warning(f"AgentBase: ä¸ºç°æœ‰æ¶ˆæ¯è‡ªåŠ¨ç”Ÿæˆmessage_id: {msg_copy['message_id'][:8]}...")
            merged.append(msg_copy)
            message_map[msg_copy['message_id']] = msg_copy
        
        # ç„¶ååˆå¹¶æ–°æ¶ˆæ¯
        for msg in new_messages:
            msg_copy = msg.copy()
            # ç¡®ä¿æ¶ˆæ¯æœ‰message_id
            if 'message_id' not in msg_copy:
                msg_copy['message_id'] = str(uuid.uuid4())
                logger.warning(f"AgentBase: ä¸ºæ–°æ¶ˆæ¯è‡ªåŠ¨ç”Ÿæˆmessage_id: {msg_copy['message_id'][:8]}...")
                
            msg_id = msg_copy['message_id']
            
            if msg_id in message_map:
                # æ›´æ–°ç°æœ‰æ¶ˆæ¯å†…å®¹
                existing = message_map[msg_id]
                if 'content' in existing:
                    existing['content'] += msg_copy.get('content', '')
                if 'show_content' in existing:                
                    existing['show_content'] += msg_copy.get('show_content', '')
            else:
                # æ·»åŠ æ–°æ¶ˆæ¯
                merged.append(msg_copy)
                message_map[msg_id] = msg_copy
        
        return merged

    def _merge_chunks(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        åˆå¹¶æ¶ˆæ¯å—ï¼Œå°†å…·æœ‰ç›¸åŒmessage_idçš„å—åˆå¹¶
        
        Args:
            chunks: æ¶ˆæ¯å—åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: åˆå¹¶åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if not chunks:
            return []
        
        merged_map = {}
        result = []
        
        for chunk in chunks:
            message_id = chunk.get('message_id')
            if not message_id:
                result.append(chunk)
                continue
                
            if message_id in merged_map:
                # åˆå¹¶å†…å®¹
                existing = merged_map[message_id]
                if 'content' in chunk:
                    existing['content'] = existing.get('content', '') + chunk['content']
                if 'show_content' in chunk:
                    existing['show_content'] = existing.get('show_content', '') + chunk['show_content']
            else:
                merged_map[message_id] = chunk.copy()
                result.append(merged_map[message_id])
        
        return result

    def convert_messages_to_str(self, messages: List[Dict[str, Any]]) -> str:
        """
        å°†æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            str: æ ¼å¼åŒ–åçš„æ¶ˆæ¯å­—ç¬¦ä¸²
        """
        logger.debug(f"AgentBase: å°† {len(messages)} æ¡æ¶ˆæ¯è½¬æ¢ä¸ºå­—ç¬¦ä¸²")
        
        messages_str_list = []
        
        for msg in messages:
            if msg['role'] == 'user':
                messages_str_list.append(f"User: {msg['content']}")
            elif msg['role'] == 'assistant':
                if 'content' in msg:
                    messages_str_list.append(f"Assistant: {msg['content']}")
                elif 'tool_calls' in msg:
                    messages_str_list.append(f"Assistant: Tool calls: {msg['tool_calls']}")
            elif msg['role'] == 'tool':
                messages_str_list.append(f"Tool: {msg['content']}")
        
        result = "\n".join(messages_str_list) or "None"
        logger.debug(f"AgentBase: è½¬æ¢åå­—ç¬¦ä¸²é•¿åº¦: {len(result)}")
        return result
    
    def _judge_delta_content_type(self, 
                                 delta_content: str, 
                                 all_tokens_str: str, 
                                 tag_type: List[str] = None) -> str:
        """
        åˆ¤æ–­å¢é‡å†…å®¹çš„ç±»å‹
        
        Args:
            delta_content: å¢é‡å†…å®¹
            all_tokens_str: æ‰€æœ‰tokenå­—ç¬¦ä¸²
            tag_type: æ ‡ç­¾ç±»å‹åˆ—è¡¨
            
        Returns:
            str: å†…å®¹ç±»å‹
        """
        if tag_type is None:
            tag_type = []
            
        start_tag = [f"<{tag}>" for tag in tag_type]
        end_tag = [f"</{tag}>" for tag in tag_type]
        
        # æ„é€ ç»“æŸæ ‡ç­¾çš„æ‰€æœ‰å¯èƒ½å‰ç¼€
        end_tag_process_list = []
        for tag in end_tag:
            for i in range(len(tag)):
                end_tag_process_list.append(tag[:i + 1])    
        
        last_tag = None
        last_tag_index = None
        
        all_tokens_str = (all_tokens_str + delta_content).strip()
        
        # æŸ¥æ‰¾æœ€åå‡ºç°çš„æ ‡ç­¾
        for tag in start_tag + end_tag:
            index = all_tokens_str.rfind(tag)
            if index != -1:
                if last_tag_index is None or index > last_tag_index:
                    last_tag = tag
                    last_tag_index = index
        
        if last_tag is None:
            return "tag"
            
        if last_tag in start_tag:
            if last_tag_index + len(last_tag) == len(all_tokens_str):
                return 'tag'    
            for end_tag_process in end_tag_process_list:
                if all_tokens_str.endswith(end_tag_process):
                    return 'unknown'
            else:
                return last_tag.replace('<', '').replace('>', '')
        elif last_tag in end_tag:
            return 'tag'

    def _collect_and_log_stream_output(self, stream_generator: Generator[List[Dict[str, Any]], None, None]) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ”¶é›†æµå¼è¾“å‡ºå¹¶åœ¨æœ€åè®°å½•å®Œæ•´æ—¥å¿—çš„è£…é¥°å™¨æ–¹æ³•
        
        Args:
            stream_generator: æµå¼è¾“å‡ºç”Ÿæˆå™¨
            
        Yields:
            List[Dict[str, Any]]: æµå¼è¾“å‡ºçš„æ¶ˆæ¯å—
        """
        agent_name = self.__class__.__name__
        logger.debug(f"ğŸ” {agent_name} å¼€å§‹æ”¶é›†æµå¼è¾“å‡º...")
        
        all_output_chunks = []
        chunk_count = 0
        
        try:
            for chunk_batch in stream_generator:
                chunk_count += 1
                all_output_chunks.extend(chunk_batch)
                yield chunk_batch
        except Exception as e:
            logger.error(f"ğŸ” {agent_name} åœ¨æµå¼å¤„ç†ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            logger.error(f"ğŸ” {agent_name} å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            raise
        finally:
            logger.debug(f"ğŸ” {agent_name} æµå¼å¤„ç†å®Œæˆï¼Œæ€»å…±æ”¶é›† {len(all_output_chunks)} ä¸ªchunks")
            
            # åˆå¹¶ç›¸åŒmessage_idçš„chunks
            merged_messages = self._merge_chunks(all_output_chunks)
            logger.debug(f"ğŸ” {agent_name} åˆå¹¶åå¾—åˆ° {len(merged_messages)} æ¡æ¶ˆæ¯")
            
            # è®°å½•å®Œæ•´è¾“å‡ºæ—¥å¿—
            self._log_agent_output(merged_messages)

    def _extract_usage_from_chunk(self, chunk) -> Optional[Dict[str, Any]]:
        """
        ä»LLM chunkä¸­æå–usageä¿¡æ¯çš„ç»Ÿä¸€å‡½æ•°
        
        æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°ç”¨äºåœ¨æµå¼å¤„ç†ä¸­ä¸ºæ¶ˆæ¯å—æ·»åŠ usageä¿¡æ¯ï¼Œä¾›å‰ç«¯æ˜¾ç¤ºä½¿ç”¨ã€‚
        çœŸæ­£çš„tokenç»Ÿè®¡æ˜¯åœ¨_track_streaming_token_usageä¸­å®Œæˆçš„ï¼Œåªç»Ÿè®¡æœ€ç»ˆçš„usageä¿¡æ¯ï¼Œé¿å…é‡å¤ç»Ÿè®¡ã€‚
        
        ä¸¤ä¸ªç”¨é€”ï¼š
        1. æ¶ˆæ¯ä¼ é€’ï¼šæ¯ä¸ªæ¶ˆæ¯å—éƒ½åŒ…å«å½“å‰å¯ç”¨çš„usageä¿¡æ¯ï¼ˆå¯èƒ½æ˜¯ä¸­é—´çŠ¶æ€ï¼‰
        2. ç»Ÿè®¡æ±‡æ€»ï¼šåªåœ¨æœ€åç»Ÿè®¡ä¸€æ¬¡å®Œæ•´çš„usageä¿¡æ¯
        
        Args:
            chunk: LLMå“åº”chunk
            
        Returns:
            Optional[Dict[str, Any]]: æå–çš„usageä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›None
        """
        if hasattr(chunk, 'usage') and chunk.usage:
            usage = chunk.usage
            
            # å¤„ç†ä¸åŒæ¨¡å‹çš„ç‰¹æ®Šå­—æ®µ - ä¿®å¤å¯¹è±¡è®¿é—®æ–¹å¼
            cached_tokens = 0
            reasoning_tokens = 0
            
            # å¤„ç†prompt_tokens_details
            if hasattr(usage, 'prompt_tokens_details') and usage.prompt_tokens_details:
                if hasattr(usage.prompt_tokens_details, 'cached_tokens'):
                    cached_tokens = getattr(usage.prompt_tokens_details, 'cached_tokens', 0) or 0
            else:
                # å…¼å®¹æ€§å¤„ç†ï¼ŒæŸäº›æ¨¡å‹å¯èƒ½ç›´æ¥åœ¨usageå¯¹è±¡ä¸Šæœ‰cached_tokens
                cached_tokens = getattr(usage, 'cached_tokens', 0) or 0
            
            # å¤„ç†completion_tokens_details  
            if hasattr(usage, 'completion_tokens_details') and usage.completion_tokens_details:
                if hasattr(usage.completion_tokens_details, 'reasoning_tokens'):
                    reasoning_tokens = getattr(usage.completion_tokens_details, 'reasoning_tokens', 0) or 0
            else:
                # å…¼å®¹æ€§å¤„ç†ï¼ŒæŸäº›æ¨¡å‹å¯èƒ½ç›´æ¥åœ¨usageå¯¹è±¡ä¸Šæœ‰reasoning_tokens
                reasoning_tokens = getattr(usage, 'reasoning_tokens', 0) or 0
            
            return {
                'prompt_tokens': getattr(usage, 'prompt_tokens', 0),
                'completion_tokens': getattr(usage, 'completion_tokens', 0),
                'total_tokens': getattr(usage, 'total_tokens', 0),
                'cached_tokens': cached_tokens,
                'reasoning_tokens': reasoning_tokens
            }
        return None
