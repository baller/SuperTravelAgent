"""
AgentController é‡æ„ç‰ˆæœ¬

æ™ºèƒ½ä½“æ§åˆ¶å™¨ï¼Œè´Ÿè´£åè°ƒå¤šä¸ªæ™ºèƒ½ä½“ååŒå·¥ä½œã€‚
æ”¹è¿›äº†ä»£ç ç»“æ„ã€é”™è¯¯å¤„ç†ã€æ—¥å¿—è®°å½•å’Œå¯ç»´æŠ¤æ€§ã€‚

ä½œè€…: Multi-Agent Framework Team
æ—¥æœŸ: 2024
ç‰ˆæœ¬: 2.0 (é‡æ„ç‰ˆ)
"""

import json
import uuid
import re
import os
import sys
import datetime
import traceback
import time
from typing import List, Dict, Any, Optional, Generator

from .agent_base import AgentBase
from .task_analysis_agent.task_analysis_agent import TaskAnalysisAgent
from .executor_agent.executor_agent import ExecutorAgent
from .task_summary_agent.task_summary_agent import TaskSummaryAgent
from .planning_agent.planning_agent import PlanningAgent
from .observation_agent.observation_agent import ObservationAgent
from .direct_executor_agent.direct_executor_agent import DirectExecutorAgent
from .task_decompose_agent.task_decompose_agent import TaskDecomposeAgent
from agents.utils.logger import logger


class AgentController:
    """
    æ™ºèƒ½ä½“æ§åˆ¶å™¨
    
    è´Ÿè´£åè°ƒå¤šä¸ªæ™ºèƒ½ä½“ååŒå·¥ä½œï¼Œç®¡ç†ä»»åŠ¡æ‰§è¡Œæµç¨‹ï¼Œ
    åŒ…æ‹¬ä»»åŠ¡åˆ†æã€è§„åˆ’ã€æ‰§è¡Œã€è§‚å¯Ÿå’Œæ€»ç»“ç­‰é˜¶æ®µã€‚
    """

    # é»˜è®¤é…ç½®å¸¸é‡
    DEFAULT_MAX_LOOP_COUNT = 10
    DEFAULT_MESSAGE_LIMIT = 10000
    
    # å·¥ä½œç›®å½•æ¨¡æ¿
    WORKSPACE_TEMPLATE = "/tmp/sage/{session_id}"

    def __init__(self, model: Any, model_config: Dict[str, Any], system_prefix: str = ""):
        """
        åˆå§‹åŒ–æ™ºèƒ½ä½“æ§åˆ¶å™¨
        
        Args:
            model: è¯­è¨€æ¨¡å‹å®ä¾‹
            model_config: æ¨¡å‹é…ç½®å‚æ•°
            system_prefix: ç³»ç»Ÿå‰ç¼€æç¤º
        """
        self.model = model
        self.model_config = model_config
        self.system_prefix = system_prefix
        self._init_agents()
        
        # æ€»ä½“tokenç»Ÿè®¡
        self.overall_token_stats = {
            'total_input_tokens': 0,
            'total_output_tokens': 0,
            'total_cached_tokens': 0,
            'total_reasoning_tokens': 0,
            'total_calls': 0,
            'total_execution_time': 0,
            'workflow_start_time': None,
            'workflow_end_time': None
        }
        
        logger.info("AgentController: æ™ºèƒ½ä½“æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        
    def _init_agents(self) -> None:
        """
        åˆå§‹åŒ–æ‰€æœ‰å¿…éœ€çš„æ™ºèƒ½ä½“
        
        ä½¿ç”¨å…±äº«çš„æ¨¡å‹å®ä¾‹ä¸ºæ‰€æœ‰æ™ºèƒ½ä½“è¿›è¡Œåˆå§‹åŒ–ã€‚
        """
        logger.debug("AgentController: åˆå§‹åŒ–å„ç±»æ™ºèƒ½ä½“")
        
        self.task_analysis_agent = TaskAnalysisAgent(
            self.model, self.model_config, system_prefix=self.system_prefix
        )
        self.executor_agent = ExecutorAgent(
            self.model, self.model_config, system_prefix=self.system_prefix
        )
        self.task_summary_agent = TaskSummaryAgent(
            self.model, self.model_config, system_prefix=self.system_prefix
        )
        self.planning_agent = PlanningAgent(
            self.model, self.model_config, system_prefix=self.system_prefix
        )
        self.observation_agent = ObservationAgent(
            self.model, self.model_config, system_prefix=self.system_prefix
        )
        self.direct_executor_agent = DirectExecutorAgent(
            self.model, self.model_config, system_prefix=self.system_prefix
        )
        self.task_decompose_agent = TaskDecomposeAgent(
            self.model, self.model_config, system_prefix=self.system_prefix
        )
        
        logger.info("AgentController: æ‰€æœ‰æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")

    def run_stream(self, 
                   input_messages: List[Dict[str, Any]], 
                   tool_manager: Optional[Any] = None, 
                   session_id: Optional[str] = None, 
                   deep_thinking: bool = True, 
                   summary: bool = True,
                   max_loop_count: int = DEFAULT_MAX_LOOP_COUNT,
                   deep_research: bool = True) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œæ™ºèƒ½ä½“å·¥ä½œæµå¹¶æµå¼è¾“å‡ºç»“æœ
        
        Args:
            input_messages: è¾“å…¥æ¶ˆæ¯å­—å…¸åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨å®ä¾‹
            session_id: ä¼šè¯ID
            deep_thinking: æ˜¯å¦è¿›è¡Œä»»åŠ¡åˆ†æ
            summary: æ˜¯å¦ç”Ÿæˆä»»åŠ¡æ€»ç»“
            max_loop_count: æœ€å¤§å¾ªç¯æ¬¡æ•°
            deep_research: æ˜¯å¦è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼ˆå®Œæ•´æµç¨‹ï¼‰
            
        Yields:
            List[Dict[str, Any]]: è‡ªä¸Šæ¬¡yieldä»¥æ¥çš„æ–°æ¶ˆæ¯å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªæ¶ˆæ¯åŒ…å«ï¼š
            - message_id: æ¶ˆæ¯çš„å”¯ä¸€æ ‡è¯†ç¬¦
            - å…¶ä»–æ ‡å‡†æ¶ˆæ¯å­—æ®µï¼ˆroleã€contentã€typeç­‰ï¼‰
        """
        # é‡ç½®æ‰€æœ‰agentçš„tokenç»Ÿè®¡
        logger.info("AgentController: é‡ç½®æ‰€æœ‰Agentçš„Tokenç»Ÿè®¡")
        self.reset_all_token_stats()
        
        # è®°å½•å·¥ä½œæµå¼€å§‹æ—¶é—´
        self.overall_token_stats['workflow_start_time'] = time.time()
        logger.info(f"AgentController: å¼€å§‹æµå¼å·¥ä½œæµï¼Œä¼šè¯ID: {session_id}")
        
        try:
            # å‡†å¤‡ä¼šè¯å’Œæ¶ˆæ¯
            session_id = self._prepare_session_id(session_id)
            all_messages = self._prepare_initial_messages(input_messages)
            
            # è®¾ç½®æ‰§è¡Œä¸Šä¸‹æ–‡
            context = self._setup_execution_context(session_id)
            
            # æ‰§è¡Œå·¥ä½œæµ
            if deep_research:
                yield from self._execute_full_workflow(
                    all_messages=all_messages,
                    tool_manager=tool_manager,
                    context=context,
                    session_id=session_id,
                    deep_thinking=deep_thinking,
                    summary=summary,
                    max_loop_count=max_loop_count
                )
            else:
                yield from self._execute_direct_workflow(
                    all_messages=all_messages,
                    tool_manager=tool_manager,
                    context=context,
                    session_id=session_id
                )
            
            logger.info(f"AgentController: æµå¼å·¥ä½œæµå®Œæˆï¼Œä¼šè¯ID: {session_id}")
            
        except Exception as e:
            logger.error(f"AgentController: æµå¼å·¥ä½œæµæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            yield from self._handle_workflow_error(e)
        finally:
            # è®°å½•å·¥ä½œæµç»“æŸæ—¶é—´å¹¶æ‰“å°ç»Ÿè®¡
            self.overall_token_stats['workflow_end_time'] = time.time()
            self.print_comprehensive_token_stats()

    def _prepare_session_id(self, session_id: Optional[str]) -> str:
        """
        å‡†å¤‡ä¼šè¯ID
        
        Args:
            session_id: å¯é€‰çš„ä¼šè¯ID
            
        Returns:
            str: å‡†å¤‡å¥½çš„ä¼šè¯ID
        """
        if session_id is None:
            session_id = str(uuid.uuid1())
            logger.info(f"AgentController: ç”Ÿæˆæ–°ä¼šè¯ID: {session_id}")
        return session_id

    def _prepare_initial_messages(self, input_messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        å‡†å¤‡åˆå§‹æ¶ˆæ¯
        
        Args:
            input_messages: è¾“å…¥æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: å‡†å¤‡å¥½çš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.debug("AgentController: å‡†å¤‡åˆå§‹æ¶ˆæ¯")
        
        # ä¸ºæ¶ˆæ¯æ·»åŠ message_idï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
        all_messages = []
        for msg in input_messages.copy():
            if 'message_id' not in msg:
                msg = {**msg, 'message_id': str(uuid.uuid4())} 
            all_messages.append(msg)
        
        # æ¸…ç†è¿‡é•¿çš„æ¶ˆæ¯å†å²
        all_messages = self._trim_message_history(all_messages)
        
        logger.info(f"AgentController: åˆå§‹åŒ–æ¶ˆæ¯æ•°é‡: {len(all_messages)}")
        return all_messages

    def _trim_message_history(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä¿®å‰ªæ¶ˆæ¯å†å²ï¼Œé˜²æ­¢å†…å®¹è¿‡é•¿
        
        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: ä¿®å‰ªåçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.debug("AgentController: æ£€æŸ¥å¹¶ä¿®å‰ªæ¶ˆæ¯å†å²")
        
        # å¦‚æœæ¶ˆæ¯å†…å®¹è¿‡é•¿ï¼Œåˆ é™¤éå…³é”®æ¶ˆæ¯
        start_index = 0
        while len(json.dumps(messages)) > self.DEFAULT_MESSAGE_LIMIT and start_index < len(messages):
            if messages[start_index]['role'] == 'user' or messages[start_index].get('type') == 'final_answer':
                start_index += 1
                continue
            else:
                del messages[start_index]
                continue
        
        logger.debug(f"AgentController: ä¿®å‰ªåæ¶ˆæ¯æ•°é‡: {len(messages)}")
        return messages

    def _setup_execution_context(self, session_id: str) -> Dict[str, Any]:
        """
        è®¾ç½®æ‰§è¡Œä¸Šä¸‹æ–‡
        
        Args:
            session_id: ä¼šè¯ID
            
        Returns:
            Dict[str, Any]: æ‰§è¡Œä¸Šä¸‹æ–‡å­—å…¸
        """
        logger.debug("AgentController: è®¾ç½®æ‰§è¡Œä¸Šä¸‹æ–‡")
        
        current_time_str = datetime.datetime.now().strftime('%Y-%m-%d %A %H:%M:%S')
        file_workspace = self.WORKSPACE_TEMPLATE.format(session_id=session_id)
        
        # åˆ›å»ºå·¥ä½œç›®å½•
        if os.path.exists(file_workspace):
            logger.debug("AgentController: ä½¿ç”¨ç°æœ‰å·¥ä½œç›®å½•")
        else:
            os.makedirs(file_workspace, exist_ok=True)
            logger.debug(f"AgentController: åˆ›å»ºå·¥ä½œç›®å½•: {file_workspace}")
        
        context = {
            'current_time': current_time_str, 
            'file_workspace': file_workspace
        }
        
        logger.info(f"AgentController: æ‰§è¡Œä¸Šä¸‹æ–‡è®¾ç½®å®Œæˆ: {context}")
        return context

    def _execute_full_workflow(self, 
                             all_messages: List[Dict[str, Any]],
                             tool_manager: Optional[Any],
                             context: Dict[str, Any],
                             session_id: str,
                             deep_thinking: bool,
                             summary: bool,
                             max_loop_count: int) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµ
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            deep_thinking: æ˜¯å¦è¿›è¡Œæ·±åº¦æ€è€ƒ
            summary: æ˜¯å¦ç”Ÿæˆæ€»ç»“
            max_loop_count: æœ€å¤§å¾ªç¯æ¬¡æ•°
            
        Yields:
            List[Dict[str, Any]]: å·¥ä½œæµè¾“å‡ºçš„æ¶ˆæ¯å—
        """
        logger.info("AgentController: å¼€å§‹æ‰§è¡Œå®Œæ•´å·¥ä½œæµ")
        
        # 1. ä»»åŠ¡åˆ†æé˜¶æ®µ
        if deep_thinking:
            all_messages = yield from self._execute_task_analysis_phase(
                all_messages, tool_manager, context, session_id
            )
        
        # 2. ä»»åŠ¡åˆ†è§£é˜¶æ®µ
        all_messages = yield from self._execute_task_decomposition_phase(
            all_messages, tool_manager, context, session_id
        )
        
        # 3. è§„åˆ’-æ‰§è¡Œ-è§‚å¯Ÿå¾ªç¯
        all_messages = yield from self._execute_main_loop(
            all_messages, tool_manager, context, session_id, max_loop_count
        )
        
        # 4. ä»»åŠ¡æ€»ç»“é˜¶æ®µ
        if summary:
            all_messages = yield from self._execute_task_summary_phase(
                all_messages, tool_manager, context, session_id
            )

    def _execute_task_analysis_phase(self, 
                                   all_messages: List[Dict[str, Any]],
                                   tool_manager: Optional[Any],
                                   context: Dict[str, Any],
                                   session_id: str) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œä»»åŠ¡åˆ†æé˜¶æ®µ
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            
        Yields:
            List[Dict[str, Any]]: ä»»åŠ¡åˆ†æè¾“å‡ºçš„æ¶ˆæ¯å—
            
        Returns:
            List[Dict[str, Any]]: æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.info("AgentController: å¼€å§‹ä»»åŠ¡åˆ†æé˜¶æ®µ")
        
        analysis_chunks = []
        for chunk in self.task_analysis_agent.run_stream(
            messages=all_messages, 
            tool_manager=tool_manager, 
            context=context, 
            session_id=session_id
        ):
            analysis_chunks.append(chunk)
            all_messages = self.task_analysis_agent._merge_messages(all_messages, chunk)
            yield chunk
        
        logger.info(f"AgentController: ä»»åŠ¡åˆ†æé˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(analysis_chunks)} ä¸ªå—")
        return all_messages

    def _execute_task_decomposition_phase(self, 
                                        all_messages: List[Dict[str, Any]],
                                        tool_manager: Optional[Any],
                                        context: Dict[str, Any],
                                        session_id: str) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œä»»åŠ¡åˆ†è§£é˜¶æ®µ
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            
        Yields:
            List[Dict[str, Any]]: ä»»åŠ¡åˆ†è§£è¾“å‡ºçš„æ¶ˆæ¯å—
            
        Returns:
            List[Dict[str, Any]]: æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.info("AgentController: å¼€å§‹ä»»åŠ¡åˆ†è§£é˜¶æ®µ")
        
        decompose_chunks = []
        for chunk in self.task_decompose_agent.run_stream(
            messages=all_messages, 
            tool_manager=tool_manager, 
            context=context, 
            session_id=session_id
        ):
            decompose_chunks.append(chunk)
            all_messages = self.task_analysis_agent._merge_messages(all_messages, chunk)
            yield chunk
        
        logger.info(f"AgentController: ä»»åŠ¡åˆ†è§£é˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(decompose_chunks)} ä¸ªå—")
        return all_messages

    def _execute_main_loop(self, 
                         all_messages: List[Dict[str, Any]],
                         tool_manager: Optional[Any],
                         context: Dict[str, Any],
                         session_id: str,
                         max_loop_count: int) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œä¸»è¦çš„è§„åˆ’-æ‰§è¡Œ-è§‚å¯Ÿå¾ªç¯
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            max_loop_count: æœ€å¤§å¾ªç¯æ¬¡æ•°
            
        Yields:
            List[Dict[str, Any]]: å¾ªç¯è¾“å‡ºçš„æ¶ˆæ¯å—
            
        Returns:
            List[Dict[str, Any]]: æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.info("AgentController: å¼€å§‹è§„åˆ’-æ‰§è¡Œ-è§‚å¯Ÿå¾ªç¯")
        
        loop_count = 0
        while True:
            loop_count += 1
            logger.info(f"AgentController: å¼€å§‹ç¬¬ {loop_count} è½®å¾ªç¯")
            
            if loop_count > max_loop_count:
                logger.warning(f"AgentController: è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•° {max_loop_count}ï¼Œåœæ­¢å·¥ä½œæµ")
                break

            # è§„åˆ’é˜¶æ®µ
            all_messages = yield from self._execute_planning_phase(
                all_messages, tool_manager, context, session_id
            )
            
            # æ‰§è¡Œé˜¶æ®µ
            all_messages = yield from self._execute_execution_phase(
                all_messages, tool_manager, context, session_id
            )
            
            # è§‚å¯Ÿé˜¶æ®µ
            all_messages, should_break = yield from self._execute_observation_phase(
                all_messages, tool_manager, context, session_id
            )
            
            if should_break:
                break
        
        logger.info("AgentController: è§„åˆ’-æ‰§è¡Œ-è§‚å¯Ÿå¾ªç¯å®Œæˆ")
        return all_messages

    def _execute_planning_phase(self, 
                              all_messages: List[Dict[str, Any]],
                              tool_manager: Optional[Any],
                              context: Dict[str, Any],
                              session_id: str) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œè§„åˆ’é˜¶æ®µ
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            
        Yields:
            List[Dict[str, Any]]: è§„åˆ’è¾“å‡ºçš„æ¶ˆæ¯å—
            
        Returns:
            List[Dict[str, Any]]: æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.info("AgentController: å¼€å§‹è§„åˆ’é˜¶æ®µ")
        
        plan_chunks = []
        for chunk in self.planning_agent.run_stream(
            messages=all_messages, 
            tool_manager=tool_manager, 
            context=context, 
            session_id=session_id
        ):
            plan_chunks.append(chunk)
            all_messages = self.task_analysis_agent._merge_messages(all_messages, chunk)
            yield chunk
        
        logger.info(f"AgentController: è§„åˆ’é˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(plan_chunks)} ä¸ªå—")
        return all_messages

    def _execute_execution_phase(self, 
                               all_messages: List[Dict[str, Any]],
                               tool_manager: Optional[Any],
                               context: Dict[str, Any],
                               session_id: str) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œæ‰§è¡Œé˜¶æ®µ
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            
        Yields:
            List[Dict[str, Any]]: æ‰§è¡Œè¾“å‡ºçš„æ¶ˆæ¯å—
            
        Returns:
            List[Dict[str, Any]]: æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.info("AgentController: å¼€å§‹æ‰§è¡Œé˜¶æ®µ")
        
        exec_chunks = []
        for chunk in self.executor_agent.run_stream(
            messages=all_messages, 
            tool_manager=tool_manager, 
            context=context, 
            session_id=session_id
        ):
            exec_chunks.append(chunk)
            all_messages = self.task_analysis_agent._merge_messages(all_messages, chunk)
            yield chunk
        
        logger.info(f"AgentController: æ‰§è¡Œé˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(exec_chunks)} ä¸ªå—")
        return all_messages

    def _execute_observation_phase(self, 
                                 all_messages: List[Dict[str, Any]],
                                 tool_manager: Optional[Any],
                                 context: Dict[str, Any],
                                 session_id: str) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œè§‚å¯Ÿé˜¶æ®µ
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            
        Yields:
            List[Dict[str, Any]]: è§‚å¯Ÿè¾“å‡ºçš„æ¶ˆæ¯å—
            
        Returns:
            Tuple[List[Dict[str, Any]], bool]: æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨å’Œæ˜¯å¦åº”è¯¥ä¸­æ–­å¾ªç¯
        """
        logger.info("AgentController: å¼€å§‹è§‚å¯Ÿé˜¶æ®µ")
        
        obs_chunks = []
        for chunk in self.observation_agent.run_stream(
            messages=all_messages, 
            tool_manager=tool_manager, 
            context=context, 
            session_id=session_id
        ):
            obs_chunks.append(chunk)
            all_messages = self.task_analysis_agent._merge_messages(all_messages, chunk)
            yield chunk
        
        logger.info(f"AgentController: è§‚å¯Ÿé˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(obs_chunks)} ä¸ªå—")
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­å¾ªç¯
        should_break = self._check_loop_completion(all_messages)
        
        return all_messages, should_break

    def _execute_task_summary_phase(self, 
                                  all_messages: List[Dict[str, Any]],
                                  tool_manager: Optional[Any],
                                  context: Dict[str, Any],
                                  session_id: str) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œä»»åŠ¡æ€»ç»“é˜¶æ®µ
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            
        Yields:
            List[Dict[str, Any]]: æ€»ç»“è¾“å‡ºçš„æ¶ˆæ¯å—
            
        Returns:
            List[Dict[str, Any]]: æ›´æ–°åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        logger.info("AgentController: å¼€å§‹ä»»åŠ¡æ€»ç»“é˜¶æ®µ")
        
        summary_chunks = []
        for chunk in self.task_summary_agent.run_stream(
            messages=all_messages, 
            tool_manager=tool_manager, 
            context=context, 
            session_id=session_id
        ):
            summary_chunks.append(chunk)
            all_messages = self.task_analysis_agent._merge_messages(all_messages, chunk)
            yield chunk
        
        logger.info(f"AgentController: ä»»åŠ¡æ€»ç»“é˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(summary_chunks)} ä¸ªå—")
        return all_messages

    def _execute_direct_workflow(self, 
                               all_messages: List[Dict[str, Any]],
                               tool_manager: Optional[Any],
                               context: Dict[str, Any],
                               session_id: str) -> Generator[List[Dict[str, Any]], None, None]:
        """
        æ‰§è¡Œç›´æ¥å·¥ä½œæµï¼ˆä½¿ç”¨ç›´æ¥æ‰§è¡Œæ™ºèƒ½ä½“ï¼‰
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            context: æ‰§è¡Œä¸Šä¸‹æ–‡
            session_id: ä¼šè¯ID
            
        Yields:
            List[Dict[str, Any]]: ç›´æ¥æ‰§è¡Œè¾“å‡ºçš„æ¶ˆæ¯å—
        """
        logger.info("AgentController: ä½¿ç”¨ç›´æ¥æ‰§è¡Œæ™ºèƒ½ä½“")
        
        for chunk in self.direct_executor_agent.run_stream(
            messages=all_messages, 
            tool_manager=tool_manager, 
            context=context, 
            session_id=session_id
        ):
            all_messages = self.task_analysis_agent._merge_messages(all_messages, chunk)
            yield chunk
        
        logger.info("AgentController: ç›´æ¥æ‰§è¡Œæ™ºèƒ½ä½“å®Œæˆ")

    def _check_loop_completion(self, all_messages: List[Dict[str, Any]]) -> bool:
        """
        æ£€æŸ¥å¾ªç¯æ˜¯å¦åº”è¯¥å®Œæˆ
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥ä¸­æ–­å¾ªç¯
        """
        logger.debug("AgentController: æ£€æŸ¥å¾ªç¯å®Œæˆæ¡ä»¶")
        
        try:
            obs_content = all_messages[-1]['content'].replace('Observation: ', '')
            obs_result = json.loads(obs_content)
            
            if obs_result.get('is_completed', False):
                logger.info("AgentController: è§‚å¯Ÿé˜¶æ®µæŒ‡ç¤ºä»»åŠ¡å·²å®Œæˆ")
                return True
                
            if obs_result.get('needs_more_input', False):
                logger.info("AgentController: ä»»åŠ¡éœ€è¦ç”¨æˆ·æä¾›æ›´å¤šè¾“å…¥")
                clarify_msg = {
                    'role': 'assistant',
                    'content': obs_result.get('user_query', ''),
                    'type': 'final_answer',
                    'message_id': str(uuid.uuid4()),
                    'show_content': obs_result.get('user_query', '') + '\n'
                }
                all_messages.append(clarify_msg)
                return True
                
        except (json.JSONDecodeError, IndexError, KeyError) as e:
            logger.warning(f"AgentController: è§£æè§‚å¯Ÿç»“æœå¤±è´¥: {str(e)}ï¼Œç»§ç»­å¾ªç¯")
            
        return False

    def _handle_workflow_error(self, error: Exception) -> Generator[List[Dict[str, Any]], None, None]:
        """
        å¤„ç†å·¥ä½œæµæ‰§è¡Œé”™è¯¯
        
        Args:
            error: å‘ç”Ÿçš„å¼‚å¸¸
            
        Yields:
            List[Dict[str, Any]]: é”™è¯¯æ¶ˆæ¯å—
        """
        logger.error(f"AgentController: å¤„ç†å·¥ä½œæµé”™è¯¯: {str(error)}")
        
        error_message = f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(error)}"
        message_id = str(uuid.uuid4())
        
        yield [{
            'role': 'assistant',
            'content': error_message,
            'type': 'final_answer',
            'message_id': message_id,
            'show_content': error_message
        }]

    def run(self, 
            input_messages: List[Dict[str, Any]], 
            tool_manager: Optional[Any] = None, 
            session_id: Optional[str] = None, 
            deep_thinking: bool = True,
            summary: bool = True,
            max_loop_count: int = DEFAULT_MAX_LOOP_COUNT,
            deep_research: bool = True) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ™ºèƒ½ä½“å·¥ä½œæµï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
        
        Args:
            input_messages: è¾“å…¥æ¶ˆæ¯å­—å…¸åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨å®ä¾‹
            session_id: ä¼šè¯ID
            deep_thinking: æ˜¯å¦è¿›è¡Œä»»åŠ¡åˆ†æ
            summary: æ˜¯å¦ç”Ÿæˆä»»åŠ¡æ€»ç»“
            max_loop_count: æœ€å¤§å¾ªç¯æ¬¡æ•°
            deep_research: æ˜¯å¦è¿›è¡Œæ·±åº¦ç ”ç©¶ï¼ˆå®Œæ•´æµç¨‹ï¼‰
            
        Returns:
            Dict[str, Any]: åŒ…å«all_messagesã€new_messagesã€final_outputå’Œsession_idçš„ç»“æœå­—å…¸
        """
        logger.info(f"AgentController: å¼€å§‹éæµå¼å·¥ä½œæµï¼Œä¼šè¯ID: {session_id}")
        
        # é‡ç½®æ‰€æœ‰agentçš„tokenç»Ÿè®¡
        logger.info("AgentController: é‡ç½®æ‰€æœ‰Agentçš„Tokenç»Ÿè®¡")
        self.reset_all_token_stats()
        
        # è®°å½•å·¥ä½œæµå¼€å§‹æ—¶é—´
        self.overall_token_stats['workflow_start_time'] = time.time()
        
        try:
            # å‡†å¤‡ä¼šè¯å’Œæ¶ˆæ¯
            session_id = self._prepare_session_id(session_id)
            
            # åˆå§‹åŒ–æ¶ˆæ¯å’ŒçŠ¶æ€
            all_messages = input_messages.copy()
            new_messages = []
            
            logger.info(f"AgentController: åˆå§‹åŒ– {len(all_messages)} æ¡è¾“å…¥æ¶ˆæ¯")
            
            # æ ¹æ®deep_researchå‚æ•°é€‰æ‹©æ‰§è¡Œè·¯å¾„
            if deep_research:
                # å®Œæ•´æµç¨‹
                if deep_thinking:
                    all_messages, new_messages = self._execute_task_analysis_non_stream(
                        all_messages, new_messages, tool_manager
                    )
                
                # ä»»åŠ¡åˆ†è§£é˜¶æ®µ
                all_messages, new_messages = self._execute_task_decompose_non_stream(
                    all_messages, new_messages, tool_manager
                )
                
                # ä¸»å¾ªç¯
                all_messages, new_messages = self._execute_main_loop_non_stream(
                    all_messages, new_messages, tool_manager, session_id, max_loop_count
                )
                
                # æ€»ç»“é˜¶æ®µ
                if summary:
                    all_messages, new_messages, final_output = self._execute_task_summary_non_stream(
                        all_messages, new_messages, tool_manager
                    )
                else:
                    final_output = new_messages[-1] if new_messages else None
            else:
                # ç›´æ¥æ‰§è¡Œæ¨¡å¼
                direct_messages = self.direct_executor_agent.run(
                    all_messages, tool_manager, session_id=session_id
                )
                all_messages.extend(direct_messages)
                new_messages.extend(direct_messages)
                final_output = new_messages[-1] if new_messages else None
            
            logger.info(f"AgentController: éæµå¼å·¥ä½œæµå®Œæˆï¼Œä¼šè¯ID: {session_id}")
            
            return {
                'all_messages': all_messages,
                'new_messages': new_messages,
                'final_output': final_output,
                'session_id': session_id,
            }
            
        except Exception as e:
            logger.error(f"AgentController: éæµå¼å·¥ä½œæµæ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            logger.error(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            error_message = {
                'role': 'assistant',
                'content': f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}",
                'type': 'final_answer'
            }
            
            return {
                'all_messages': input_messages + [error_message],
                'new_messages': [error_message],
                'final_output': error_message,
                'session_id': session_id or str(uuid.uuid1()),
            }
        finally:
            # è®°å½•å·¥ä½œæµç»“æŸæ—¶é—´å¹¶æ‰“å°ç»Ÿè®¡
            self.overall_token_stats['workflow_end_time'] = time.time()
            self.print_comprehensive_token_stats()

    def _execute_task_analysis_non_stream(self, 
                                        all_messages: List[Dict[str, Any]], 
                                        new_messages: List[Dict[str, Any]], 
                                        tool_manager: Optional[Any]) -> tuple:
        """
        æ‰§è¡Œä»»åŠ¡åˆ†æï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            new_messages: æ–°æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            
        Returns:
            tuple: æ›´æ–°åçš„(all_messages, new_messages)
        """
        logger.info("AgentController: å¼€å§‹åˆå§‹ä»»åŠ¡åˆ†æ")
        
        analysis_messages = self.task_analysis_agent.run(all_messages, tool_manager)
        logger.info(f"AgentController: ä»»åŠ¡åˆ†æå®Œæˆï¼Œç”Ÿæˆ {len(analysis_messages)} æ¡æ¶ˆæ¯")
        
        all_messages.extend(analysis_messages)
        new_messages.extend(analysis_messages)
        
        return all_messages, new_messages

    def _execute_task_decompose_non_stream(self, 
                                         all_messages: List[Dict[str, Any]], 
                                         new_messages: List[Dict[str, Any]], 
                                         tool_manager: Optional[Any]) -> tuple:
        """
        æ‰§è¡Œä»»åŠ¡åˆ†è§£ï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            new_messages: æ–°æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            
        Returns:
            tuple: æ›´æ–°åçš„(all_messages, new_messages)
        """
        logger.info("AgentController: å¼€å§‹ä»»åŠ¡åˆ†è§£")
        
        decompose_messages = self.task_decompose_agent.run(all_messages, tool_manager)
        logger.info(f"AgentController: ä»»åŠ¡åˆ†è§£å®Œæˆï¼Œç”Ÿæˆ {len(decompose_messages)} æ¡æ¶ˆæ¯")
        
        all_messages.extend(decompose_messages)
        new_messages.extend(decompose_messages)
        
        return all_messages, new_messages

    def _execute_main_loop_non_stream(self, 
                                    all_messages: List[Dict[str, Any]], 
                                    new_messages: List[Dict[str, Any]], 
                                    tool_manager: Optional[Any], 
                                    session_id: str,
                                    max_loop_count: int) -> tuple:
        """
        æ‰§è¡Œä¸»å¾ªç¯ï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            new_messages: æ–°æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            session_id: ä¼šè¯ID
            max_loop_count: æœ€å¤§å¾ªç¯æ¬¡æ•°
            
        Returns:
            tuple: æ›´æ–°åçš„(all_messages, new_messages)
        """
        loop_count = 0
        
        while loop_count < max_loop_count:
            loop_count += 1
            logger.info(f"AgentController: å¼€å§‹ç¬¬ {loop_count} è½®è§„åˆ’-æ‰§è¡Œ-è§‚å¯Ÿå¾ªç¯")
            
            # è§„åˆ’é˜¶æ®µ
            plan_messages = self.planning_agent.run(all_messages, tool_manager)
            logger.info(f"AgentController: è§„åˆ’é˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(plan_messages)} æ¡æ¶ˆæ¯")
            all_messages.extend(plan_messages)
            new_messages.extend(plan_messages)
            
            # æ‰§è¡Œé˜¶æ®µ
            exec_messages = self.executor_agent.run(all_messages, tool_manager, session_id=session_id)
            logger.info(f"AgentController: æ‰§è¡Œé˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(exec_messages)} æ¡æ¶ˆæ¯")
            all_messages.extend(exec_messages)
            new_messages.extend(exec_messages)
            
            # è§‚å¯Ÿé˜¶æ®µ
            obs_messages = self.observation_agent.run(all_messages)
            logger.info(f"AgentController: è§‚å¯Ÿé˜¶æ®µå®Œæˆï¼Œç”Ÿæˆ {len(obs_messages)} æ¡æ¶ˆæ¯")
            all_messages.extend(obs_messages)
            new_messages.extend(obs_messages)
            
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
            should_break = self._check_task_completion(obs_messages, all_messages, new_messages)
            if should_break:
                break
        
        if loop_count >= max_loop_count:
            logger.warning(f"AgentController: è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•° {max_loop_count}ï¼Œå¼ºåˆ¶ç»“æŸ")
        
        return all_messages, new_messages

    def _check_task_completion(self, 
                             obs_messages: List[Dict[str, Any]], 
                             all_messages: List[Dict[str, Any]], 
                             new_messages: List[Dict[str, Any]]) -> bool:
        """
        æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
        
        Args:
            obs_messages: è§‚å¯Ÿæ¶ˆæ¯åˆ—è¡¨
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            new_messages: æ–°æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥ä¸­æ–­å¾ªç¯
        """
        try:
            obs_result_content = obs_messages[-1]['content'].replace('Observation: ', '')
            obs_result_json = json.loads(obs_result_content)
            
            if obs_result_json.get('is_completed', False):
                logger.info("AgentController: è§‚å¯Ÿé˜¶æ®µæŒ‡ç¤ºä»»åŠ¡å·²å®Œæˆ")
                return True
                
            if obs_result_json.get('needs_more_input', False):
                logger.info("AgentController: ä»»åŠ¡éœ€è¦ç”¨æˆ·æä¾›æ›´å¤šè¾“å…¥")
                clarify_message = {
                    'role': 'assistant',
                    'content': obs_result_json.get('user_query', ''),
                    'type': 'final_answer'
                }
                all_messages.append(clarify_message)
                new_messages.append(clarify_message)
                return True
                
        except (json.JSONDecodeError, IndexError, KeyError) as e:
            logger.warning(f"AgentController: è§‚å¯Ÿç»“æœè§£æå¤±è´¥: {str(e)}ï¼Œç»§ç»­æ‰§è¡Œ")
            
        return False

    def _execute_task_summary_non_stream(self, 
                                       all_messages: List[Dict[str, Any]], 
                                       new_messages: List[Dict[str, Any]], 
                                       tool_manager: Optional[Any]) -> tuple:
        """
        æ‰§è¡Œä»»åŠ¡æ€»ç»“ï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
        
        Args:
            all_messages: æ‰€æœ‰æ¶ˆæ¯åˆ—è¡¨
            new_messages: æ–°æ¶ˆæ¯åˆ—è¡¨
            tool_manager: å·¥å…·ç®¡ç†å™¨
            
        Returns:
            tuple: æ›´æ–°åçš„(all_messages, new_messages, final_output)
        """
        logger.info("AgentController: å¼€å§‹ä»»åŠ¡æ€»ç»“é˜¶æ®µ")
        
        summary_result = self.task_summary_agent.run(all_messages, tool_manager)
        logger.info(f"AgentController: ä»»åŠ¡æ€»ç»“å®Œæˆï¼Œç”Ÿæˆ {len(summary_result)} æ¡æ¶ˆæ¯")
        
        all_messages.extend(summary_result)
        new_messages.extend(summary_result)
        
        # è·å–æœ€ç»ˆè¾“å‡ºï¼ˆæœ€åä¸€æ¡æ­£å¸¸æ¶ˆæ¯ï¼‰
        final_output = next(
            (m for m in reversed(summary_result) if m.get('type') == 'final_answer'),
            summary_result[-1] if summary_result else None
        )
        
        return all_messages, new_messages, final_output

    def _is_task_complete(self, messages: List[Dict[str, Any]]) -> bool:
        """
        åŸºäºè¯„ä¼°è¾“å‡ºæ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            bool: ä»»åŠ¡æ˜¯å¦å®Œæˆ
        """
        logger.debug("AgentController: æ£€æŸ¥ä»»åŠ¡å®ŒæˆçŠ¶æ€")
        
        # æŸ¥æ‰¾å·¥å…·å“åº”æ¶ˆæ¯
        tool_response = next(
            (msg for msg in messages 
             if msg.get('role') == 'tool' and 
                msg.get('tool_call_id', '').startswith('decision_')),
            None
        )
        
        if not tool_response or not tool_response.get('content'):
            return False
            
        content = tool_response['content']
        
        try:
            # å°è¯•ç›´æ¥è§£æä¸ºJSON
            result = json.loads(content)
        except json.JSONDecodeError:
            # å°è¯•ä»markdownä»£ç å—ä¸­æå–JSON
            code_block_pattern = r'```(?:json)?\n([\s\S]*?)\n```'
            match = re.search(code_block_pattern, content)
            if match:
                try:
                    result = json.loads(match.group(1))
                except json.JSONDecodeError:
                    return False
            else:
                return False
                
        is_complete = result.get('task_status', '') == 'completed'
        logger.debug(f"AgentController: ä»»åŠ¡å®ŒæˆçŠ¶æ€: {is_complete}")
        return is_complete

    def _collect_agent_stats(self) -> Dict[str, Any]:
        """
        æ”¶é›†æ‰€æœ‰agentçš„tokenç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Any]: æ±‡æ€»çš„ç»Ÿè®¡ä¿¡æ¯
        """
        all_stats = {}
        total_stats = {
            'total_input_tokens': 0,
            'total_output_tokens': 0,
            'total_cached_tokens': 0,
            'total_reasoning_tokens': 0,
            'total_calls': 0,
            'agents': {}
        }
        
        # æ”¶é›†å„ä¸ªagentçš„ç»Ÿè®¡
        agents = [
            self.task_analysis_agent,
            self.executor_agent,
            self.task_summary_agent,
            self.planning_agent,
            self.observation_agent,
            self.direct_executor_agent,
            self.task_decompose_agent
        ]
        
        for agent in agents:
            if hasattr(agent, 'get_token_stats'):
                stats = agent.get_token_stats()
                all_stats[stats['agent_name']] = stats
                
                # ç´¯åŠ åˆ°æ€»ç»Ÿè®¡
                total_stats['total_input_tokens'] += stats['total_input_tokens']
                total_stats['total_output_tokens'] += stats['total_output_tokens']
                total_stats['total_cached_tokens'] += stats['total_cached_tokens']
                total_stats['total_reasoning_tokens'] += stats['total_reasoning_tokens']
                total_stats['total_calls'] += stats['total_calls']
                total_stats['agents'][stats['agent_name']] = stats
        
        return {
            'individual_stats': all_stats,
            'total_stats': total_stats
        }
    
    def print_comprehensive_token_stats(self):
        """
        æ‰“å°ç»¼åˆçš„tokenä½¿ç”¨ç»Ÿè®¡
        """
        stats = self._collect_agent_stats()
        total = stats['total_stats']
        
        print("\n" + "="*80)
        print("ğŸš€ AgentController ç»¼åˆTokenä½¿ç”¨ç»Ÿè®¡")
        print("="*80)
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"  ğŸ“ æ€»è°ƒç”¨æ¬¡æ•°: {total['total_calls']}")
        print(f"  ğŸ“¥ æ€»è¾“å…¥tokens: {total['total_input_tokens']:,}")
        print(f"  ğŸ“¤ æ€»è¾“å‡ºtokens: {total['total_output_tokens']:,}")
        print(f"  ğŸƒ æ€»ç¼“å­˜tokens: {total['total_cached_tokens']:,}")
        print(f"  ğŸ§  æ€»æ¨ç†tokens: {total['total_reasoning_tokens']:,}")
        print(f"  ğŸ”¢ æ€»è®¡tokens: {total['total_input_tokens'] + total['total_output_tokens']:,}")
        
        if self.overall_token_stats['workflow_start_time'] and self.overall_token_stats['workflow_end_time']:
            workflow_time = self.overall_token_stats['workflow_end_time'] - self.overall_token_stats['workflow_start_time']
            print(f"  â±ï¸  å·¥ä½œæµæ€»è€—æ—¶: {workflow_time:.2f}ç§’")
        
        # å„agentè¯¦ç»†ç»Ÿè®¡
        print(f"\nğŸ¤– å„Agentè¯¦ç»†ç»Ÿè®¡:")
        for agent_name, agent_stats in total['agents'].items():
            if agent_stats['total_calls'] > 0:  # åªæ˜¾ç¤ºæœ‰è°ƒç”¨çš„agent
                print(f"\n  ğŸ”¹ {agent_name}:")
                print(f"    ğŸ“ è°ƒç”¨: {agent_stats['total_calls']} æ¬¡")
                print(f"    ğŸ“¥ è¾“å…¥: {agent_stats['total_input_tokens']:,} tokens")
                print(f"    ğŸ“¤ è¾“å‡º: {agent_stats['total_output_tokens']:,} tokens")
                if agent_stats['total_cached_tokens'] > 0:
                    print(f"    ğŸƒ ç¼“å­˜: {agent_stats['total_cached_tokens']:,} tokens")
                if agent_stats['total_reasoning_tokens'] > 0:
                    print(f"    ğŸ§  æ¨ç†: {agent_stats['total_reasoning_tokens']:,} tokens")
                print(f"    ğŸ”¢ å°è®¡: {agent_stats['total_input_tokens'] + agent_stats['total_output_tokens']:,} tokens")
                
                # æ˜¾ç¤ºæ­¥éª¤è¯¦æƒ…
                if agent_stats.get('step_details'):
                    print(f"    ğŸ“‹ æ­¥éª¤è¯¦æƒ…:")
                    for detail in agent_stats['step_details']:
                        print(f"      â€¢ {detail['step']}: è¾“å…¥{detail['input_tokens']}, è¾“å‡º{detail['output_tokens']}, è€—æ—¶{detail['execution_time']}s")
        
        print("\n" + "="*80)
        
    def reset_all_token_stats(self):
        """
        é‡ç½®æ‰€æœ‰agentçš„tokenç»Ÿè®¡
        """
        agents = [
            self.task_analysis_agent,
            self.executor_agent,
            self.task_summary_agent,
            self.planning_agent,
            self.observation_agent,
            self.direct_executor_agent,
            self.task_decompose_agent
        ]
        
        for agent in agents:
            if hasattr(agent, 'reset_token_stats'):
                agent.reset_token_stats()
        
        # é‡ç½®æ€»ä½“ç»Ÿè®¡
        self.overall_token_stats = {
            'total_input_tokens': 0,
            'total_output_tokens': 0,
            'total_cached_tokens': 0,
            'total_reasoning_tokens': 0,
            'total_calls': 0,
            'total_execution_time': 0,
            'workflow_start_time': None,
            'workflow_end_time': None
        }
        
        logger.info("AgentController: æ‰€æœ‰Tokenç»Ÿè®¡å·²é‡ç½®")
